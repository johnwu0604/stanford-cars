{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32692fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-16 14:38:14.039731: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/john/anaconda3/envs/aml/lib/python3.7/site-packages/cv2/../../lib64:\n",
      "2021-12-16 14:38:14.039838: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import csv\n",
    "import mlflow.keras\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import densenet\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, Callback\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "429577ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-12-16 11:45:45--  https://github.com/fchollet/deep-learning-models/releases/download/v0.8/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "Resolving github.com (github.com)... 140.82.113.3\n",
      "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/64878964/f5b4b85e-fa1e-11e7-9a46-5fbe25b60245?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211216%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211216T194544Z&X-Amz-Expires=300&X-Amz-Signature=95acbb78231c9887c01ae965f202e680e6280fc8f0320b7f72f99db2da6507c0&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=64878964&response-content-disposition=attachment%3B%20filename%3Ddensenet121_weights_tf_dim_ordering_tf_kernels_notop.h5&response-content-type=application%2Foctet-stream [following]\n",
      "--2021-12-16 11:45:46--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/64878964/f5b4b85e-fa1e-11e7-9a46-5fbe25b60245?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211216%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211216T194544Z&X-Amz-Expires=300&X-Amz-Signature=95acbb78231c9887c01ae965f202e680e6280fc8f0320b7f72f99db2da6507c0&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=64878964&response-content-disposition=attachment%3B%20filename%3Ddensenet121_weights_tf_dim_ordering_tf_kernels_notop.h5&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 30011760 (29M) [application/octet-stream]\n",
      "Saving to: ‘densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
      "\n",
      "densenet121_weights 100%[===================>]  28.62M  14.6MB/s    in 2.0s    \n",
      "\n",
      "2021-12-16 11:45:48 (14.6 MB/s) - ‘densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [30011760/30011760]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/fchollet/deep-learning-models/releases/download/v0.8/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc9d9dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './blobstore/cars'\n",
    "img_width, img_height = 224, 224\n",
    "# num_train_samples = 8144\n",
    "# num_validation_samples = 8041\n",
    "num_train_samples = 100\n",
    "num_validation_samples = 10\n",
    "epochs = 1\n",
    "batch_size = 8\n",
    "num_classes = 196"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "743e924f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    base_model = densenet.DenseNet121(input_shape=(img_width, img_height, 3),\n",
    "                                      weights='densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                                      include_top=False,\n",
    "                                      pooling='avg')\n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = True\n",
    "\n",
    "    x = base_model.output\n",
    "    x = Dense(1000, kernel_regularizer=regularizers.l1_l2(0.01), activity_regularizer=regularizers.l2(0.01))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dense(500, kernel_regularizer=regularizers.l1_l2(0.01), activity_regularizer=regularizers.l2(0.01))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a77476ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = []\n",
    "\n",
    "with open(data_dir + '/names.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=';')\n",
    "    for row in csv_reader:\n",
    "        class_names.append(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee585f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8144 images belonging to 196 classes.\n",
      "Found 8041 images belonging to 196 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data_dir = data_dir + '/car_data/train'\n",
    "validation_data_dir = data_dir + '/car_data/test'\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    zoom_range=0.2,\n",
    "    rotation_range = 5,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12ee4ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-16 14:38:36.734507: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/john/anaconda3/envs/aml/lib/python3.7/site-packages/cv2/../../lib64:\n",
      "2021-12-16 14:38:36.734858: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-12-16 14:38:36.734928: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (JOHN-WU): /proc/driver/nvidia/version does not exist\n",
      "2021-12-16 14:38:36.735514: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc', 'mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea17bcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', patience=8, verbose=1, min_delta=1e-4)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=4, verbose=1, min_delta=1e-4)\n",
    "callbacks_list = [early_stop, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "064a68ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.tensorflow.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79352a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021/12/16 14:48:51 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '8355fa7260ae432ab0ced9dbae4a6bee', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 75s 5s/step - loss: 391.9749 - acc: 0.0104 - mse: 0.0051 - val_loss: 613766.8125 - val_acc: 0.0000e+00 - val_mse: 0.0100 - lr: 0.0010\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp7dwqr6ra/model/data/model/assets\n"
     ]
    }
   ],
   "source": [
    "model_history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch = num_train_samples // batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=num_validation_samples // batch_size,\n",
    "    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16ca54f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-16 14:45:55.425665: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/john/projects/stanford-cars/model/data/model/assets\n"
     ]
    }
   ],
   "source": [
    "mlflow.keras.save_model(model, 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3090a0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-16 14:27:48.358411: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c2b3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate_generator(validation_generator, steps=None, max_queue_size=10, workers=1, use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6295213",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_generator(validation_generator, steps=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=1)\n",
    "predicted = np.argmax(pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fa2c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_one(model):\n",
    "    image_batch, classes_batch = next(validation_generator)\n",
    "    predicted_batch = model.predict(image_batch)\n",
    "    for k in range(0,image_batch.shape[0]):\n",
    "        image = image_batch[k]\n",
    "        pred = predicted_batch[k]\n",
    "        the_pred = np.argmax(pred)\n",
    "        predicted = class_names[the_pred]\n",
    "        val_pred = max(pred)\n",
    "        the_class = np.argmax(classes_batch[k])\n",
    "        value = class_names[np.argmax(classes_batch[k])]\n",
    "        plt.figure(k)\n",
    "        isTrue = (the_pred == the_class)\n",
    "        plt.title(str(isTrue) + ' - class: ' + value + ' - ' + 'predicted: ' + predicted + '[' + str(val_pred) + ']')\n",
    "        plt.imshow(image)\n",
    "\n",
    "predict_one(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aml",
   "language": "python",
   "name": "aml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
