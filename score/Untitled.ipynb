{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6670ee49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import json\n",
    "from PIL import Image\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "160484eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn import functional as F\n",
    "from torchmetrics.functional.classification import accuracy\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from torch.optim import Adam\n",
    "from torchvision import models\n",
    "from typing import Optional\n",
    "from torch.nn import Module\n",
    "\n",
    "BN_TYPES = (nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d)\n",
    "\n",
    "def _make_trainable(module: Module) -> None:\n",
    "    '''Unfreezes a given module.\n",
    "    Args:\n",
    "        module: The module to unfreeze\n",
    "    '''\n",
    "    for param in module.parameters():\n",
    "        param.requires_grad = True\n",
    "    module.train()\n",
    "\n",
    "\n",
    "def _recursive_freeze(module: Module,\n",
    "                      train_bn: bool = True) -> None:\n",
    "    '''Freezes the layers of a given module.\n",
    "    Args:\n",
    "        module: The module to freeze\n",
    "        train_bn: If True, leave the BatchNorm layers in training mode\n",
    "    '''\n",
    "    children = list(module.children())\n",
    "    if not children:\n",
    "        if not (isinstance(module, BN_TYPES) and train_bn):\n",
    "            for param in module.parameters():\n",
    "                param.requires_grad = False\n",
    "            module.eval()\n",
    "        else:\n",
    "            # Make the BN layers trainable\n",
    "            _make_trainable(module)\n",
    "    else:\n",
    "        for child in children:\n",
    "            _recursive_freeze(module=child, train_bn=train_bn)\n",
    "\n",
    "\n",
    "def freeze(module: Module,\n",
    "           n: Optional[int] = None,\n",
    "           train_bn: bool = True) -> None:\n",
    "    '''Freezes the layers up to index n (if n is not None).\n",
    "    Args:\n",
    "        module: The module to freeze (at least partially)\n",
    "        n: Max depth at which we stop freezing the layers. If None, all\n",
    "            the layers of the given module will be frozen.\n",
    "        train_bn: If True, leave the BatchNorm layers in training mode\n",
    "    '''\n",
    "    children = list(module.children())\n",
    "    n_max = len(children) if n is None else int(n)\n",
    "\n",
    "    for child in children[:n_max]:\n",
    "        _recursive_freeze(module=child, train_bn=train_bn)\n",
    "\n",
    "    for child in children[n_max:]:\n",
    "        _make_trainable(module=child)\n",
    "\n",
    "class ResNet152(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, \n",
    "                train_bn: bool = True,\n",
    "                lr: float = 1e-3,\n",
    "                num_workers: int = 4,\n",
    "                hidden_1: int = 1024,\n",
    "                hidden_2: int = 512,\n",
    "                epoch_freeze: int = 8,\n",
    "                total_steps: int = 15,\n",
    "                pct_start: float = 0.2,\n",
    "                anneal_strategy: str = 'cos',\n",
    "                **kwargs):\n",
    "        super().__init__()\n",
    "        self.train_bn = train_bn\n",
    "        self.lr = lr\n",
    "        self.num_workers = num_workers\n",
    "        self.hidden_1 = hidden_1\n",
    "        self.hidden_2 = hidden_2\n",
    "        self.epoch_freeze = epoch_freeze\n",
    "        self.total_steps = total_steps\n",
    "        self.pct_start = pct_start\n",
    "        self.anneal_strategy = anneal_strategy\n",
    "        self.save_hyperparameters()\n",
    "        self.__build_model()\n",
    "        \n",
    "    def __build_model(self):\n",
    "        num_target_classes = 196\n",
    "        backbone = models.resnet152(pretrained=True)\n",
    "    \n",
    "        _layers = list(backbone.children())[:-1]\n",
    "        self.feature_extractor = nn.Sequential(*_layers)\n",
    "\n",
    "        _fc_layers = [nn.Linear(2048, self.hidden_1),\n",
    "                     nn.Linear(self.hidden_1, self.hidden_2),\n",
    "                     nn.Linear(self.hidden_2, num_target_classes)]\n",
    "        self.fc = nn.Sequential(*_fc_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = x.squeeze(-1).squeeze(-1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "    def train(self, mode=True):\n",
    "        super().train(mode=mode)\n",
    "        epoch = self.current_epoch\n",
    "        if epoch < self.epoch_freeze and mode:\n",
    "            freeze(module=self.feature_extractor,\n",
    "                   train_bn=self.train_bn) \n",
    "            \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_logits = self.forward(x)\n",
    "        train_loss = F.cross_entropy(y_logits, y)\n",
    "        acc = accuracy(y_logits, y)\n",
    "        self.log('acc', acc, prog_bar=True)\n",
    "        return train_loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_logits = self.forward(x)\n",
    "        val_loss = F.cross_entropy(y_logits, y)\n",
    "        acc = accuracy(y_logits, y)\n",
    "        self.log('val_loss', val_loss, prog_bar=True)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        if self.current_epoch < self.epoch_freeze:\n",
    "            optimizer = Adam(filter(lambda p: p.requires_grad, self.parameters()), lr=self.lr)\n",
    "            return optimizer\n",
    "        else:\n",
    "            optimizer = Adam(filter(lambda p: p.requires_grad, self.parameters()), lr=self.lr)     \n",
    "            scheduler = OneCycleLR(optimizer,\n",
    "                            max_lr=self.lr,\n",
    "                            total_steps=self.total_steps,\n",
    "                            pct_start=self.pct_start, anneal_strategy=self.anneal_strategy)\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c2547868",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet152()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "366b0300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dir = './model'\n",
    "model.load_state_dict(torch.load(model_dir + '/model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a9ad9ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "487ab774",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open('sedan.jpg').convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6d913225",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, std = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
    "preprocess = transforms.Compose([\n",
    "        transforms.Resize((400, 400)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std, inplace=True)\n",
    "    ])\n",
    "\n",
    "image_preprocessed = preprocess(image)\n",
    "batch_image_tensor = torch.unsqueeze(image_preprocessed, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "84ed1539",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(batch_image_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f80698a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1393, -0.1973,  0.3063, -0.1849,  0.2180, -0.0921,  0.1180,  2.7630,\n",
       "          0.0236,  0.0516, -0.2295, -0.3622,  0.0693,  0.0716, -0.5010,  0.1693,\n",
       "          0.2861, -0.3926,  0.0649,  0.2917, -0.9888,  0.2420, -0.6086,  0.3551,\n",
       "          0.3682,  0.1606,  0.1521, -0.0119, -0.3442,  0.2192, -0.3687, -0.2173,\n",
       "         -0.1415, -0.3838, -0.7095, -0.1164, -0.5318, -0.1630, -0.0683, -0.1332,\n",
       "          0.4097, -0.7286,  0.3359, -0.3529,  0.3977, -0.3562, -0.1357, -0.1311,\n",
       "         -0.0160,  0.2227, -0.6012, -0.3036, -0.1461,  0.2659,  0.0095, -0.4154,\n",
       "          0.0045, -0.0515, -0.1052,  0.0067, -0.4168,  0.2203,  0.0409,  0.0870,\n",
       "         -0.1089,  0.4164,  0.4776, -0.3142, -0.3883, -0.0778, -0.3655,  0.0586,\n",
       "          0.1143, -0.1125,  0.3734, -0.0491,  0.2777,  0.1619, -0.2813, -0.0590,\n",
       "         -0.1060,  0.0215,  0.0240,  0.0913,  0.1136,  0.5203, -0.4383, -0.6874,\n",
       "         -0.3167,  0.1992,  0.0772,  0.1687, -0.1164,  0.1934,  0.1289, -0.5103,\n",
       "         -0.2795, -0.4316,  0.0401, -0.4381,  0.2120,  0.6234, -0.5177, -0.4835,\n",
       "          0.3518, -0.5955, -0.3172, -0.2924,  0.3381, -0.0815,  3.3279, -0.3284,\n",
       "         -0.4934,  0.3919, -0.3083, -0.3232,  0.0305,  0.2732, -0.3583,  0.4088,\n",
       "         -0.2496,  0.2203,  0.0592,  0.0760, -0.1924, -0.1922,  0.2204, -0.2033,\n",
       "          0.1685, -0.2309, -0.2961, -0.1661, -0.5463, -0.3559,  0.2254, -0.0342,\n",
       "          2.5219,  0.1165, -0.2356,  0.4127, -0.4586,  0.2945,  3.0428, -0.2359,\n",
       "         -0.1512, -0.4463, -0.1584, -0.0463,  0.2654,  0.1018, -0.1642, -0.0380,\n",
       "          0.7382, -0.7354,  0.5891,  0.3168, -0.0731,  0.2749,  0.4566, -0.2055,\n",
       "          0.0089,  0.1040, -0.4269, -0.0116, -0.2153,  0.6751, -0.6948,  0.1806,\n",
       "          0.2555, -0.9214, -0.3346, -0.3919, -0.1883,  0.3533, -0.0875,  0.7654,\n",
       "         -0.0345, -0.0746,  0.1660,  0.0958, -0.3245,  0.5110, -0.4150,  0.1051,\n",
       "         -0.4362, -0.7962,  0.1159,  0.3071,  0.4059, -0.5524, -0.3441,  0.1936,\n",
       "         -0.5238, -0.4725,  0.3341,  0.0551]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b2b2f72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, index = torch.max(output, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "84a97a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {}\n",
    "with open(model_dir + '/classes.json') as f:\n",
    "    classes = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79260929",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getKeyByValue(classes, index):\n",
    "    listOfKeys = list()\n",
    "    listOfItems = dictOfElements.items()\n",
    "    for item  in listOfItems:\n",
    "        if item[1] == valueToFind:\n",
    "            listOfKeys.append(item[0])\n",
    "    return  listOfKeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "40aef75f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "17daed8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ford F-450 Super Duty Crew Cab 2012\n"
     ]
    }
   ],
   "source": [
    "for item in classes:\n",
    "    if classes[item] == int(index[0]):\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d86822",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2d637a5dbdb3d812311006dd41aec8ac69c2eb9cc328381d255748d602d8d8ce"
  },
  "kernelspec": {
   "display_name": "aml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
